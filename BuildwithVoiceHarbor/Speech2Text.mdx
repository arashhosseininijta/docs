---
title: 'Transcribe multilingual audio files'
description: 'Transcribe fast, in multiple languages.'
icon: 'code'
---

## Speech to Text

Our advanced ASR technology is built on the robust foundation of OpenAI's Whisper, known for its exceptional performance in multilingual speech recognition. However, we've significantly enhanced its capabilities with in-house innovations, including the implementation of phonetic time-stamps. These detailed markers provide an extra layer of precision by capturing the timing of specific phonetic elements within the audio, enabling more granular analysis and synchronization.

Our ASR component support's for up to 4 languages and robust code-switching capabilities, it effortlessly transcribes audio that blends multiple languages. Its built-in automatic language detection ensures that users do not have to manually specify the language, streamlining the workflow, while precise time-stamps allow for easy navigation and review of audio content.

 ## Audio transcription without PHI reduction 

<Tip>

Transcirption is by **default** applied for the task **protect**. To have the transcription without any reduction use the **task** parameter and set it to **transcribe**.  

</Tip>

### Transcribe multilingual audio data

```python
BASE_URL = "https://voiceharbor.ai"
usage_token = "USAGE_TOKEN"
# Create a new job on the server via the class method.
job_id = VoiceHarborClient.create_job(BASE_URL, usage_token)

client = VoiceHarborClient(
    base_url=BASE_URL,
    job_id=job_id,
    token=usage_token,
    inputs_dir="./inputs/tests"
)

# Submit input files and the job file.and 
job_params = {"files": [], "task": "transcribe"}
job_params = client.submit_files(job_params)
job_file = client.submit_job(job_params)
logger.info(f"Job file created: {job_file}")
```

### Set target transcription language

```python

supported_codes = [
    "en", "fr", "es", "de"
]

BASE_URL = "https://voiceharbor.ai"
usage_token = "USAGE_TOKEN"
# Create a new job on the server via the class method.
job_id = VoiceHarborClient.create_job(BASE_URL, usage_token)

client = VoiceHarborClient(
    base_url=BASE_URL,
    job_id=job_id,
    token=usage_token,
    inputs_dir="./inputs/tests"
)

# Submit input files and the job file.and 
job_params = {"files": [], "task": "transcribe", "language":"en"}  
job_params = client.submit_files(job_params)
job_file = client.submit_job(job_params)
logger.info(f"Job file created: {job_file}")
```

### Output example

```python
{
  "speaker 1": {
    "transcription": [
      {
        "start": 0.05,
        "end": 5.27,
        "text": "The sandwich comes with ham, cheese, tomatoes, mayonnaise, pickles.",
        "words": [
          {
            "word": " The",
            "start": 0.05,
            "end": 0.55
          },
          {
            "word": " sandwich",
            "start": 0.55,
            "end": 0.93
          },
          {
            "word": " comes",
            "start": 0.93,
            "end": 1.33
          },
          {
            "word": " with",
            "start": 1.33,
            "end": 1.57
          },
          {
            "word": " ham",
            "start": 1.57,
            "end": 1.95
          },
          {
            "word": ",",
            "start": 1.95,
            "end": 2.13
          },
          {
            "word": " cheese",
            "start": 2.13,
            "end": 2.57
          },
          {
            "word": ",",
            "start": 2.57,
            "end": 2.73
          },
          {
            "word": " tomatoes",
            "start": 2.73,
            "end": 3.25
          },
          {
            "word": ",",
            "start": 3.25,
            "end": 3.55
          },
          {
            "word": " mayonnaise",
            "start": 3.55,
            "end": 3.93
          },
          {
            "word": ",",
            "start": 3.93,
            "end": 4.21
          },
          {
            "word": " pickles",
            "start": 4.21,
            "end": 4.51
          },
          {
            "word": ".",
            "start": 4.51,
            "end": 5.27
          }
        ]
      }
    ],
    "language": "en"
  }
}
```


<CardGroup cols={1}>
  <Card
    title="Python SDK"
    icon="python"
    href="https://github.com/Nijta-API/VoiceHarborSDK"
  >
    Start using our Python SDK to connect with Voice Harbor and implement voice solutions
  </Card>
</CardGroup>

### Benchmarks for top 50 supported languages 

| Language | Whisper-Large-V3 (WER) | Distil-Multi4-v0.2 (WER) | Δ (WER↓) |
|:---------|-----------------------:|------------------------:|---------:|
| English  | 8.93                  | 7.60                   | 1.33     |
| French   | 11.15                 | 11.07                  | 0.08     |
| Spanish  | 11.06                 | 8.52                   | 2.54     |
| German   | 17.75                 | 12.41                  | 5.34     |


## Good news to share with you!

<Update label="2025-07-01 Upcoming Release" description="NextGen Medical ASR">
  <Frame>
    <img className="block" src="/images/vh3asr.png" />
  </Frame>

  ### Changelog

  Looking ahead, we’re also pushing the envelope by refining our model with an extensive trove of medical data to eliminate hallucinations and boost reliability in even the most demanding environments. The Q2 realease will not only improve the recognition of complex medical terminology but also significantly mitigate transcirption errors, ensuring that results are both accurate and reliable. Whether you need rapid transcription for global communications or precise documentation in critical healthcare settings, our ASR component is designed to deliver excellence.

</Update>
